# -*- coding: utf-8 -*-
"""
Created on Sun Nov 17 16:05:37 2024

@author: Administrator
"""

# DenseNet121 Model

import os
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import gc
import psutil
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input, Dropout, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.applications import DenseNet121
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler
from tensorflow.keras.regularizers import l2

# Configure TensorFlow for optimal CPU usage
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
tf.config.threading.set_intra_op_parallelism_threads(1)
tf.config.threading.set_inter_op_parallelism_threads(1)
tf.config.set_soft_device_placement(True)

# Paths
#base_dir_1 = r'C:/Users/Administrator/Downloads/ExperimentsforImages/Multi_Modal_Datasets/HAM10000_images_part_1'
#base_dir_2 = r'C:/Users/Administrator/Downloads/ExperimentsforImages/Multi_Modal_Datasets/HAM10000_images_part_2'
#metadata_path = r'C:/Users/Administrator/Downloads/ExperimentsforImages/Multi_Modal_Datasets/HAM10000_metadata.csv'

#New path
# Define paths for the image data and metadata
image_directory = 'C:/download/HAM10000_images'  # Updated the directory path for images
metadata_path = 'E:/PhD 2022-26/陕西师范大学/Second Year 2024-25/ExperimentsforImages/HAM10000_metadata.csv'  # Path for metadata

# Load and preprocess metadata
metadata = pd.read_csv(metadata_path)
metadata_labels = metadata['dx']

# Encode labels and convert to one-hot encoding
label_encoder = LabelEncoder()
metadata_labels = label_encoder.fit_transform(metadata['dx'])
metadata_labels = to_categorical(metadata_labels, num_classes=7)

# Preprocess metadata features
metadata_features = metadata[['age', 'sex', 'localization']]
metadata_features = pd.get_dummies(metadata_features)
scaler = StandardScaler()
metadata_features = scaler.fit_transform(metadata_features)

# Data augmentation
datagen = ImageDataGenerator(
    rescale=1.0 / 255,
    validation_split=0.2,
    rotation_range=30,  # Increase rotation range to improve data variability
    width_shift_range=0.15,  # Increase shift range to improve model robustness
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.15,  # Increase zoom range for better generalization
    brightness_range=[0.7, 1.3],
    horizontal_flip=True,
    fill_mode='nearest'
)

# Generators with 128x128 image size
train_image_generator_1 = datagen.flow_from_directory(
    base_dir_1,
    target_size=(128, 128),  # Use 128x128 target size
    batch_size=64,  # Increase batch size for more stable training
    class_mode='categorical',
    subset='training',
    shuffle=True
)

train_image_generator_2 = datagen.flow_from_directory(
    base_dir_2,
    target_size=(128, 128),
    batch_size=64,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

validation_image_generator_1 = datagen.flow_from_directory(
    base_dir_1,
    target_size=(128, 128),
    batch_size=64,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

validation_image_generator_2 = datagen.flow_from_directory(
    base_dir_2,
    target_size=(128, 128),
    batch_size=64,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

# Combine batches from two generators and include metadata
def combine_generators(image_gen1, image_gen2, metadata_features):
    while True:
        image_batch1, label_batch1 = next(image_gen1)
        image_batch2, label_batch2 = next(image_gen2)
        images = np.concatenate([image_batch1, image_batch2])
        labels = np.concatenate([label_batch1, label_batch2])
        batch_indices = np.arange(images.shape[0])
        metadata_batch = metadata_features[batch_indices % metadata_features.shape[0]]
        yield [images, metadata_batch], labels
        gc.collect()

# Use the combine_generators function to create training and validation generators
train_gen = combine_generators(train_image_generator_1, train_image_generator_2, metadata_features)
val_gen = combine_generators(validation_image_generator_1, validation_image_generator_2, metadata_features)

# DenseNet121 with 128x128 input size
image_input = Input(shape=(128, 128, 3))
base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=image_input)

# Freeze initial layers in DenseNet121 to use as a feature extractor
for layer in base_model.layers[:-20]:  # Freeze fewer layers to allow more feature learning
    layer.trainable = False
for layer in base_model.layers[-20:]:
    layer.trainable = True

# Add custom layers on top of DenseNet121
x = GlobalAveragePooling2D()(base_model.output)
x = BatchNormalization()(x)
x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)  # Reduce neurons to prevent overfitting
x = BatchNormalization()(x)
x = Dropout(0.2)(x)  # Reduce dropout to prevent underfitting

# Metadata input and layers
metadata_input = Input(shape=(metadata_features.shape[1],))
y = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(metadata_input)  # Reduce number of neurons for better regularization
y = BatchNormalization()(y)
y = Dropout(0.2)(y)
y = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(y)  # Reduce number of neurons
y = BatchNormalization()(y)

# Concatenate image and metadata pathways
combined = Concatenate()([x, y])
z = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(combined)  # Reduce number of neurons
z = BatchNormalization()(z)
z = Dropout(0.3)(z)  # Adjust dropout for better regularization
output = Dense(7, activation='softmax', dtype='float32')(z)

# Final model
model = Model(inputs=[base_model.input, metadata_input], outputs=output)
model.compile(optimizer=SGD(learning_rate=1e-5, momentum=0.9, clipnorm=1.0), loss='categorical_crossentropy', metrics=['accuracy'])

# Learning rate scheduler
def lr_schedule(epoch, lr):
    if epoch > 10:
        return lr * 0.5
    return lr

# Callbacks
model_save_path = r'C:/Users/Administrator/Downloads/ExperimentsforImages/Multi_Modal_Datasets/densenet121_finetuned_model_128.h5'
checkpoint_callback = ModelCheckpoint(model_save_path, save_best_only=True, monitor='val_accuracy', mode='max')
csv_logger = CSVLogger('densenet121_training_log_128.csv', append=True)
early_stopping = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True)  # Increase patience to allow more training
lr_scheduler = LearningRateScheduler(lr_schedule)

# Train the DenseNet121-based model for 40 epochs with increased steps per epoch
history = model.fit(
    train_gen,
    epochs=15,  # Increase the number of epochs for more training
    validation_data=val_gen,
    steps_per_epoch=300,  # Increase steps per epoch to train on more data
    validation_steps=75,  # Increase validation steps
    callbacks=[checkpoint_callback, csv_logger, early_stopping, lr_scheduler, tf.keras.callbacks.LambdaCallback(
        on_epoch_end=lambda epoch, logs: print(f"Epoch {epoch+1}: Memory usage: {psutil.virtual_memory().percent}%"))],
    verbose=1  # Set verbose to 1 or 0 to reduce output
)

# Plot accuracy and loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')

plt.show()

# Print final metrics
print("Final training accuracy:", history.history['accuracy'][-1])
print("Final validation accuracy:", history.history['val_accuracy'][-1])
print("Training log saved to 'densenet121_training_log_128.csv'")
